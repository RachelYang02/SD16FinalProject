{
  "name": "Interactive Projected Art",
  "tagline": "",
  "body": "# SD16FinalProject\r\n\r\n#Interactive Projected Art\r\n\r\n##Description\r\nThis code is for an interactive art display in which viewers can change what is being displayed by changing their location and noises that they make.  Location is captured through OpenCV and a webcam. Audio is also inputted into the system, which causes the images on the projection to move.\r\n\r\n## Download, Installation, and Use\r\n### Dependencies:\r\nPrior to running our program, these packages need to be installed:\r\n* NumPy\r\n* SciPy\r\n* alsaaudio \r\n* Audioop\r\n* Pygame\r\n* Matplotlib\r\n* Argparse\r\n* OpenCV\r\n\r\n### Downloading and Installation\r\n* Download the zip file from [our website](http://rachelyang02.github.io/SD16FinalProject/)\r\n* Unzip the file into a location of your choice\r\n\r\n### How to Use\r\nSet up a projector on a blank wall in a dark room. Angle the projector so that a person can stand between the projector and the wall without casting a shadow. Have the viewer wear a bright green beanie that is easily trackable so that our program can easily find their location.  Aim a camera at the projection making sure that the person is easily visible in the frame. Before running, change the video camera index in colortrack.py.\r\n\r\n\r\n\r\n##License\r\n\r\n\r\n##Authors\r\n\r\nhttp://rachelyang02.github.io/SD16FinalProject/\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}